---
title: "adult_analysis"
output: html_document
date: "2026-01-20"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(text)
library(here)
library(reticulate)
library(umap)
library(viridis)
library(plotly)
library(purrr)
library(lsr)
library(effectsize)

# # install python environment 
# textrpp_install()

# initialize environment 
textrpp_initialize(save_profile = TRUE)

```


### measure of typicality: average cosine similarity
intuition: On average, how much does this specific thought look like every other thought in the database?
here, I calculated typicality within group (i.e., within children, within adults)


```{r import data}

master_data <- read.csv("/Users/karlaperez/Documents/projects/self-disclosure/4. Data/MASTER_DATA_LONG.csv", 
                        stringsAsFactors = FALSE)

child_data <- read.csv("~/Documents/projects/self-disclosure/4. Data/data_children.csv", 
                       stringsAsFactors = FALSE)

```

```{r clean data}

# adults' self disclosure trials -----------------------------------------------
adults_self <- master_data %>% 
  filter(trial_type == "survey-text")

# replace NAs and empty strings with "none"
adults_self$response_clean <- ifelse(is.na(adults_self$response) |
                                      trimws(adults_self$response) == "", 
                                    "none", 
                                    adults_self$response)

# remove newlines and extra spaces
adults_self$response_clean <- gsub("[\r\n]", " ", adults_self$response_clean)
adults_self$response_clean <- trimws(adults_self$response_clean)

message(paste("total adult_self rows to embed:", nrow(adults_self))) # 3000


# adults' animal fluency trials
adults_animals <- master_data %>% 
  filter(trial_type == "animal_entry")

# children's self disclosure trials --------------------------------------------
child_self <- child_data %>% 
  pivot_longer(cols = starts_with("utterance_"), 
               names_to = "utterance",
               names_prefix = "utterance_",
               values_to = "response")

# replace NAs and empty strings with "none"
child_self$response_clean <- ifelse(is.na(child_self$response) |
                                      trimws(child_self$response) == "", 
                                    "none", 
                                    child_self$response)

# remove newlines and extra spaces
child_self$response_clean <- gsub("[\r\n]", " ", child_self$response_clean)
child_self$response_clean <- trimws(child_self$response_clean)

message(paste("total child rows to embed:", nrow(child_self))) # 228


# combine adult and child data --------------------------------------------




```




```{r run child embeddings}

# run SBERT
child_embeddings_raw <- textEmbed(
  texts = child_self$response_clean,
  model = "sentence-transformers/all-distilroberta-v1",
  batch_size = 10,
  keep_token_embeddings = FALSE
)

# pull the vectors
child_vectors <- child_embeddings_raw$texts[[1]]

# MAKE SURE WE DID NOT LOSE A BATCH 
nrow(child_vectors) == nrow(child_self) # if TRUE, we're good

# if (nrow(child_vectors) < nrow(child_self)) {
#   missing_idx <- setdiff(1:nrow(child_self), as.numeric(rownames(child_vectors)))
#   message(paste("Repairing", length(missing_idx), "missing rows..."))
#   
#   repair <- textEmbed(
#     texts = child_self$response_clean[missing_idx],
#     model = "sentence-transformers/all-distilroberta-v1",
#     batch_size = 1,
#     keep_token_embeddings = FALSE
#   )
#   
#   repair_vecs <- repair$texts[[1]]
#   rownames(repair_vecs) <- missing_idx
#   child_vectors <- rbind(child_vectors, repair_vecs)
#   child_vectors <- child_vectors[order(as.numeric(rownames(child_vectors))), ]
# }
```

```{r calculate child typicality}

# typicality calculation
child_sim_matrix <- textSimilarityMatrix(child_vectors)
child_self$typicality <- (rowSums(child_sim_matrix) - 1) / (ncol(child_sim_matrix) - 1)

# 2D coordinates for child cloud
child_umap <- umap(child_vectors)
child_self$umap_1 <- child_umap$layout[,1]
child_self$umap_2 <- child_umap$layout[,2]

```

```{r visualize child semantic cloud}

ggplot(child_self, aes(x = umap_1, y = umap_2, color = typicality)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_viridis_c(option = "plasma", direction = -1) +
  theme_minimal() +
  labs(title = "Child Self-Disclosure Semantic Cloud",
       subtitle = "Dots represent individual child responses",
       color = "Typicality")
```


```{r}

# mark which rows are skips from original child responses onto vectors
child_data_long$is_skip <- is.na(child_self$response) | trimws(child_self$response) == ""

child_data_long$subject_id <- child_self$subject_id
child_data_long$age_at_test <- child_self$age_at_test
child_data_long$original_response <- child_self$response

child_data_long <- child_data_long %>% 
  select(subject_id, age_at_test, original_response, is_skip, everything())


child_final_metrics <- child_data_long %>%
  group_by(subject_id) %>%
  group_split() %>%
  map_dfr(function(df_child) {
    
    # count skips
    total_skips <- sum(df_child$is_skip)
    
    # get only real responses
    real_responses <- df_child %>% filter(!is_skip)
    
    diversity <- NA
    
    if(nrow(real_responses) >= 2) {
      # 3. Use the numeric matrix math directly
      # We extract the embedding columns (ignoring our metadata columns)
      vectors <- as.matrix(real_responses[, 6:773])
      
      # Manual Cosine Similarity Matrix:
      # Normalize rows
      norm_vecs <- vectors / sqrt(rowSums(vectors^2))
      # Dot product gives the similarity matrix
      sim_matrix <- norm_vecs %*% t(norm_vecs)
      
      # Remove self-similarity (the diagonal of 1s)
      diag(sim_matrix) <- NA
      
      # Diversity = 1 - average similarity
      diversity <- 1 - mean(sim_matrix, na.rm = TRUE)
    }
    
    data.frame(
      subject_id = df_child$subject_id[1],
      age = first(df_child$age_at_test),
      skip_count = total_skips,
      semantic_diversity = diversity
    )
  })

print(child_final_metrics)

```

```{r}
# 1. Simple Linear Regression
age_model <- lm(semantic_diversity ~ age, data = child_final_metrics)

# 2. View the Results
summary(age_model)

# 3. Visualize with a Regression Line
library(ggplot2)
ggplot(child_final_metrics, aes(x = age, y = semantic_diversity)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", color = "blue") +
  theme_minimal() +
  labs(title = "Effect of Age on Semantic Diversity",
       x = "Age (Years)",
       y = "Semantic Diversity (Breadth)")

```

```{r}
# Multiple Regression: Age + Skips
interaction_model <- lm(semantic_diversity ~ age + skip_count, data = child_final_metrics)

summary(interaction_model)
```

```{r}
# 1. Pearson Correlation for Age vs Diversity
cor_test <- cor.test(child_final_metrics$age, child_final_metrics$semantic_diversity)

# 2. Check the Skip Interaction
# Does the number of skips predict how diverse their remaining thoughts are?
skip_cor <- cor.test(child_final_metrics$skip_count, child_final_metrics$semantic_diversity)

print(paste("Correlation (Age & Diversity):", round(cor_test$estimate, 3), "p =", round(cor_test$p.value, 3)))
print(paste("Correlation (Skips & Diversity):", round(skip_cor$estimate, 3), "p =", round(skip_cor$p.value, 3)))
```


```{r}

adult_data_long <- adult_vectors
adult_data_long$subject_id <- adult_self$prolific_id
adult_data_long$response_text <- adult_self$response

adult_data_long$is_skip <- is.na(adult_data_long$response_text) | 
                            trimws(adult_data_long$response_text) == ""

adult_data_long <- adult_data_long %>% 
  select(subject_id, response_text, is_skip, everything())

adult_final_metrics <- adult_data_long %>%
  group_by(subject_id) %>%
  group_split() %>%
  map_dfr(function(df_adult) {
    real_responses <- df_adult %>% filter(!is_skip)
    diversity <- NA
    if(nrow(real_responses) >= 2) {
      vectors <- as.matrix(real_responses[, 5:772])
      norm_vecs <- vectors / sqrt(rowSums(vectors^2))
      sim_matrix <- norm_vecs %*% t(norm_vecs)
      diag(sim_matrix) <- NA
      diversity <- 1 - mean(sim_matrix, na.rm = TRUE)
    }
    data.frame(subject_id = df_adult$subject_id[1], semantic_diversity = diversity, group = "Adult")
  })

print(adult_final_metrics)

```


```{r}

comparison_df <- rbind(
  child_final_metrics %>% select(subject_id, semantic_diversity) %>% mutate(group = "Child"),
  adult_final_metrics %>% select(subject_id, semantic_diversity) %>% mutate(group = "Adult")
)

ggplot(comparison_df, aes(x = semantic_diversity, fill = group)) +
  geom_density(alpha = 0.5) + # Shows the 'shape' of each group
  geom_boxplot(width = 0.1, position = position_nudge(y = -0.05), alpha = 0.3) + # Adds the median/quartiles
  scale_fill_manual(values = c("Child" = "#FF9999", "Adult" = "#66B2FF")) +
  theme_minimal() +
  labs(title = "Is the Child's Self-Concept Less Diverse than the Adult's?",
       subtitle = "Density Plot of Within-Subject Semantic Diversity",
       x = "Semantic Diversity (1 - Mean Similarity)",
       y = "Density")

```

```{r}

t_result <- t.test(semantic_diversity ~ group, data = comparison_df)

print(t_result)

# Cohen's d
cohensD(semantic_diversity ~ group, data = comparison_df)


```

# control for verbosity

```{r verbosity test}

library(stringr)

# 1. Calculate word counts for the long-format data
child_data_long$word_count <- str_count(child_data_long$original_response, "\\w+")

# 2. Aggregate to the subject level (19 children)
child_word_stats <- child_data_long %>%
  filter(!is_skip) %>%
  group_by(subject_id) %>%
  summarize(mean_word_count = mean(word_count, na.rm = TRUE))

# 3. Join with your metrics
child_final_metrics <- child_final_metrics %>%
  left_join(child_word_stats, by = "subject_id")

# 4. The "Confound Check" Correlation
confound_test <- cor.test(child_final_metrics$mean_word_count, 
                          child_final_metrics$semantic_diversity)

print(confound_test)

```

```{r}

# 1. Calculate word counts for the long-format data
adult_data_long$word_count <- str_count(adult_data_long$response_text, "\\w+")

# 2. Aggregate to the subject level (19 children)
adult_word_stats <- adult_data_long %>%
  filter(!is_skip) %>%
  group_by(subject_id) %>%
  summarize(mean_word_count = mean(word_count, na.rm = TRUE))

# 3. Join with your metrics
adult_final_metrics <- adult_final_metrics %>%
  left_join(adult_word_stats, by = "subject_id")

# 4. The "Confound Check" Correlation
confound_test <- cor.test(adult_final_metrics$mean_word_count, 
                          adult_final_metrics$semantic_diversity)

print(confound_test)


```



```{r}
ggplot(child_final_metrics, aes(x = mean_word_count, y = semantic_diversity, color = age)) +
  geom_point(size = 4) +
  geom_smooth(method = "lm", se = FALSE, color = "black", linetype = "dashed") +
  theme_minimal() +
  labs(title = "Confound Check: Word Count vs. Diversity",
       x = "Average Word Count per Response",
       y = "Semantic Diversity Score")
```


```{r}

combined_final_metrics <- rbind(
  adult_final_metrics %>% select(subject_id, mean_word_count, semantic_diversity) %>%
    mutate(group = "Adult"),
  child_final_metrics %>% select(subject_id, mean_word_count, semantic_diversity) %>% 
    mutate(group = "Child"))


# 1. Run the ANCOVA model
# We are looking for the effect of 'group' (Child vs Adult) 
# while 'holding constant' the mean_word_count
ancova_model <- lm(semantic_diversity ~ mean_word_count + group, data = combined_final_metrics)

# 2. View the results
summary(ancova_model)

# 3. Get the "Adjusted Means"
# This tells you the diversity scores AFTER controlling for word count
library(emmeans)
adj_means <- emmeans(ancova_model, "group")
print(adj_means)

```

```{r}
# calculate effect size for ANCOVA
eta_squared(ancova_model, partial = TRUE)

```
```{r}
# 1. Ensure you have the Typicality score and Word Count in your Child dataframe
# This assumes 'child_data_long' has a column 'adult_typicality' we calculated earlier

child_data_long <- left_join(child_self %>% select(subject_id, adult), child_data_long, by = "subject_id")



# 2. Run the ANCOVA (using age as a continuous predictor this time)
maturity_model <- lm(adult_typicality ~ word_count + age_at_test, 
                     data = child_data_long %>% filter(!is_skip))

# 3. View results
summary(maturity_model)

# 4. Calculate Effect Size
library(effectsize)
eta_squared(maturity_model, partial = TRUE)
```

## adult response analysis 

```{r run adult embeddings}

# adults_self

# run SBERT, minutes from start:  6.387
adult_embeddings_raw <- textEmbed(
  texts = adults_self$response_clean,
  model = "sentence-transformers/all-distilroberta-v1",
  batch_size = 10,
  keep_token_embeddings = FALSE
)

# check if we lost any rows, if TRUE, we're good to go
nrow(adults_self) == nrow(adult_embeddings_raw$texts[[1]])

# pull the vectors
adult_vectors <- adult_embeddings_raw$texts[[1]]

# # if FALSE, run the missing batch
# adult_vectors <- adult_embeddings_raw$texts[[1]]
# 
# # find missing rows
# missing_indices <- setdiff(1:nrow(adults_self), as.numeric(rownames(adult_vectors)))
# 
# # embed missing rows
# repair_adults <- textEmbed(
#   texts = adults_self$response_clean[missing_indices],
#   model = "sentence-transformers/all-distilroberta-v1",
#   batch_size = 1
# )
# 
# # combine and sort
# final_adult_vectors <- rbind(adult_vectors, repair_adults$texts[[1]])
# final_adult_vectors <- final_adult_vectors[order(as.numeric(rownames(final_adult_vectors))), ]

```

```{r calculate adult typicality}

# typicality calculation
adults_sim_matrix <- textSimilarityMatrix(adult_vectors)
adults_self$typicality <- (rowSums(adults_sim_matrix) - 1) / (ncol(adults_sim_matrix) - 1) # how else can we calculate typicality??

# 2D coordinates for adult cloud
adults_umap <- umap(adult_vectors)
adults_self$umap_1 <- adults_umap$layout[,1]
adults_self$umap_2 <- adults_umap$layout[,2]

```

```{r visualize adult semantic cloud}

ggplot(adults_self, aes(x = umap_1, y = umap_2, color = typicality)) +
  geom_point(alpha = 0.4, size = 2) +
  scale_color_viridis_c(option = "plasma", direction = -1) +
  theme_minimal() +
  labs(title = "Adult Self-Disclosure Semantic Cloud",
       subtitle = "Dots represent individual adult responses",
       color = "Typicality")
```

## joint analysis (child and adult)

```{r merge child and adult data}

child_to_merge <- child_self %>%
  mutate(age_group = "child") %>%
  select(age_group, response = response_clean)

adult_to_merge <- adults_self %>%
  mutate(age_group = "adult") %>%
  select(age_group, response = response_clean)

# combine responses
combined_data <- bind_rows(adult_to_merge, child_to_merge)

# combine vectors 
combined_vectors <- rbind(adult_vectors, child_vectors)

message(paste("Total combined responses:", nrow(combined_data)))

```


```{r combined typicality}

# typicality calculation
combined_sim_matrix <- textSimilarityMatrix(combined_vectors)
combined_data$joint_typicality <- (rowSums(combined_sim_matrix) - 1) / (ncol(combined_sim_matrix) - 1)

# 2D coordinates for joint cloud
joint_umap_results <- umap(combined_vectors)
combined_data$umap_1 <- joint_umap_results$layout[,1]
combined_data$umap_2 <- joint_umap_results$layout[,2]
```

```{r}
# combine child and adult vectors
all_vectors <- rbind(as.matrix(child_vectors[, 1:768]), 
                     as.matrix(adult_vectors[, 1:768]))

# calculate the mean similarity of a random subset
get_random_sim <- function(pool) {
  # randomly pick 228 indices for "fake children"
  fake_child_idx <- sample(1:nrow(pool), 228)
  fake_adult_idx <- setdiff(1:nrow(pool), fake_child_idx)
  
  # normalize and calculate similarity
  child_n <- pool[fake_child_idx, ] / sqrt(rowSums(pool[fake_child_idx, ]^2))
  adult_n <- pool[fake_adult_idx, ] / sqrt(rowSums(pool[fake_adult_idx, ]^2))
  
  # return average cross-group similarity
  return(mean(tcrossprod(child_n, adult_n)))
}

# run the simulation 1,000 times
set.seed(12526)
null_distribution <- replicate(1000, get_random_sim(all_vectors))

# compare to your ACTUAL observed similarity
observed_sim <- mean(cross_sim_matrix) # The mean of our 228x3000 matrix

# 5. Calculate p-value
p_value <- sum(null_distribution <= observed_sim) / 1000
message(paste("Observed Similarity:", round(observed_sim, 4)))
message(paste("Permutation p-value:", p_value))

```

```{r}


# Function to calculate internal diversity for a set of vectors
calculate_diversity <- function(vectors) {
  if (nrow(vectors) < 2) return(NA)
  # Calculate similarity matrix
  sim_matrix <- textSimilarityMatrix(vectors)
  # Diversity = 1 - average similarity (excluding the diagonal)
  # Higher score = more diverse/spread out thoughts
  diag(sim_matrix) <- NA
  return(1 - mean(sim_matrix, na.rm = TRUE))
}

# 1. Calculate for Children
child_diversity <- child_vectors %>%
  group_by(subject_id) %>%
  group_split() %>%
  purrr::map_dfr(~data.frame(
    subject_id = .x$subject_id[1],
    diversity = calculate_diversity(as.matrix(.x[, 1:768])),
    age_group = "child"
  ))

# 2. Calculate for Adults (Assuming adults_self_long exists)
adult_diversity <- adults_self_long %>%
  group_by(subject_id) %>%
  group_split() %>%
  purrr::map_dfr(~data.frame(
    subject_id = .x$subject_id[1],
    diversity = calculate_diversity(as.matrix(.x[, 1:768])),
    age_group = "adult"
  ))

# 3. Combine for comparison
all_diversity <- rbind(child_diversity, adult_diversity)



```


```{r cross-group typicality}

# view dimensions
message(paste("Child Vectors Dim:", paste(dim(child_vectors), collapse="x")))
message(paste("Adult Vectors Dim:", paste(dim(adult_vectors), collapse="x")))

# extract only the numeric 768 columns
child_m <- as.matrix(child_vectors[, 1:768])
adult_m <- as.matrix(adult_vectors[, 1:768])

# handle NAs 
child_m[is.na(child_m)] <- 0
adult_m[is.na(adult_m)] <- 0

# normalize
child_norm <- child_m / sqrt(rowSums(child_m^2))
adult_norm <- adult_m / sqrt(rowSums(adult_m^2))

# matrix multiplication: tcrossprod expects (A, B) and calculates A %*% t(B)
sim_matrix <- tcrossprod(child_norm, adult_norm)

message(paste("Resulting Matrix Dim:", paste(dim(sim_matrix), collapse="x")))

child_self$adult_typicality <- rowMeans(sim_matrix)

```

```{r cross group typicality comparisons}

# top 10 most adult-like child disclosures
child_self %>%
  arrange(desc(adult_typicality)) %>%
  select(response, adult_typicality, age_at_test) %>%
  head(10)

# top 10 most child-like child disclosures
child_self %>%
  arrange(adult_typicality) %>%
  select(response, adult_typicality, age_at_test) %>%
  head(10)

```

```{r visualize child and adult data}

ggplot(combined_data, aes(x = umap_1, y = umap_2, color = age_group)) +
  geom_point(alpha = 0.4, size = 1) +
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) + 
  theme_minimal() +
  labs(title = "Integrated Semantic Cloud",
       subtitle = "Adult (Purple) vs. Child (Yellow) Self-Disclosures",
       x = "Joint Semantic Dim 1", y = "Joint Semantic Dim 2") +
  guides(color = guide_legend(override.aes = list(alpha = 1, size = 3)))

ggplot(combined_data, aes(x = umap_1, y = umap_2, color = age_group)) +
  geom_point(alpha = 0.4, size = 1) +
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) + 
  theme_minimal() +
  labs(title = "Integrated Semantic Cloud",
       subtitle = "Adult (Purple) vs. Child (Yellow) Self-Disclosures",
       x = "Joint Semantic Dim 1", y = "Joint Semantic Dim 2") +
  guides(color = guide_legend(override.aes = list(alpha = 1, size = 3)))


```

```{r interactive joint map}

p_joint <- ggplot(combined_data, aes(x = umap_1, y = umap_2, 
                                     color = age_group,
                                     text = response)) +
  geom_point(alpha = 0.5) +
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) +
  theme_minimal()

ggplotly(p_joint, tooltip = "text")

```

```{r}

ggplot(combined_data, aes(x = umap_1, y = umap_2, color = age_group)) +
  geom_point(alpha = 0.5, size = 1.5) + 
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) +
  theme_minimal() +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-3, 10)) + 
  labs(title = "Semantic Intersection")
```

```{r}

ggplot(combined_data, aes(x = umap_1, y = umap_2, color = age_group)) +
  geom_point(alpha = 0.5, size = 1.5) + 
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) +
  theme_minimal() +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-3, 10)) + 
  labs(title = "zoomed View") +
  facet_wrap(~age_group)

```

```{r}

child_narrow <- child_self %>% 
  select(subject_id, response_clean, typicality, umap_1, umap_2)

adult_narrow <- adults_self %>% 
  select(prolific_id, response_clean, typicality, umap_1, umap_2) %>% 
  rename(subject_id = prolific_id)

combined_data_ids <- rbind(child_narrow, adult_narrow) %>% 
   mutate(age_group = ifelse(startsWith(as.character(subject_id), "WKM"), 
                            "child", 
                            "adult"))

combined_data_ids %>% 
  filter(age_group == "adult") %>% 
  ggplot(aes(x = umap_1, y = umap_2, color = subject_id)) +
  geom_point(alpha = 0.5, size = 1.5) + 
  theme_minimal() +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-6, 6)) + 
  labs(title = "Adults Semantic Cloud",
       subtitle = "Each color represents an individual participant") +
  theme(legend.position = "none")


```

```{r}

combined_data_ids %>% 
  filter(age_group == "child") %>% 
  ggplot(aes(x = umap_1, y = umap_2, color = subject_id)) +
  geom_point(alpha = 0.5, size = 1.5) + 
  theme_minimal() +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-6, 6)) + 
  labs(title = "Children's Semantic Cloud",
       subtitle = "Each color represents an individual participant") +
  theme(legend.position = "none")

```



```{r}
# test for semantic maturity 

# 1. Ensure you have the Typicality score and Word Count in your Child dataframe
# This assumes 'child_data_long' has a column 'adult_typicality' we calculated earlier

# 2. Run the ANCOVA (using age as a continuous predictor this time)
maturity_model <- lm(adult_typicality ~ word_count + age_at_test, 
                     data = child_data_long %>% filter(!is_skip))

# 3. View results
summary(maturity_model)

# 4. Calculate Effect Size
library(effectsize)
eta_squared(maturity_model, partial = TRUE)
```

