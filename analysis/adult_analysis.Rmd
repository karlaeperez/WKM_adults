---
title: "adult_analysis"
output: html_document
date: "2026-01-20"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(text)
library(here)
library(reticulate)
library(umap)
library(viridis)
library(plotly)

# # install python environment 
# textrpp_install()

# initialize environment 
textrpp_initialize(save_profile = TRUE)

```

```{r import data}

master_data <- read.csv("/Users/karlaperez/Documents/projects/self-disclosure/4. Data/MASTER_DATA_LONG.csv", 
                        stringsAsFactors = FALSE)

child_data <- read.csv("~/Documents/projects/self-disclosure/4. Data/data_children.csv", 
                       stringsAsFactors = FALSE)

```

```{r clean data}

# adults' self disclosure trials -----------------------------------------------
adults_self <- master_data %>% 
  filter(trial_type == "survey-text")

# replace NAs and empty strings with "none"
adults_self$response_clean <- ifelse(is.na(adults_self$response) |
                                      trimws(adults_self$response) == "", 
                                    "none", 
                                    adults_self$response)

# remove newlines and extra spaces
adults_self$response_clean <- gsub("[\r\n]", " ", adults_self$response_clean)
adults_self$response_clean <- trimws(adults_self$response_clean)

message(paste("total adult_self rows to embed:", nrow(adults_self))) # 3000


# adults' animal fluency trials
adults_animals <- master_data %>% 
  filter(trial_type == "animal_entry")

# children's self disclosure trials --------------------------------------------
child_self <- child_data %>% 
  pivot_longer(cols = starts_with("utterance_"), 
               names_to = "utterance",
               names_prefix = "utterance_",
               values_to = "response")

# replace NAs and empty strings with "none"
child_self$response_clean <- ifelse(is.na(child_self$response) |
                                      trimws(child_self$response) == "", 
                                    "none", 
                                    child_self$response)

# remove newlines and extra spaces
child_self$response_clean <- gsub("[\r\n]", " ", child_self$response_clean)
child_self$response_clean <- trimws(child_self$response_clean)

message(paste("total child rows to embed:", nrow(child_self))) # 228


```

```{r run child embeddings}

# run SBERT
child_embeddings_raw <- textEmbed(
  texts = child_self$response_clean,
  model = "sentence-transformers/all-distilroberta-v1",
  batch_size = 10,
  keep_token_embeddings = FALSE
)

# pull the vectors
child_vectors <- child_embeddings_raw$texts[[1]]

# MAKE SURE WE DID NOT LOSE A BATCH 
nrow(child_vectors) == nrow(child_self) # if TRUE, we're good

# if (nrow(child_vectors) < nrow(child_self)) {
#   missing_idx <- setdiff(1:nrow(child_self), as.numeric(rownames(child_vectors)))
#   message(paste("Repairing", length(missing_idx), "missing rows..."))
#   
#   repair <- textEmbed(
#     texts = child_self$response_clean[missing_idx],
#     model = "sentence-transformers/all-distilroberta-v1",
#     batch_size = 1,
#     keep_token_embeddings = FALSE
#   )
#   
#   repair_vecs <- repair$texts[[1]]
#   rownames(repair_vecs) <- missing_idx
#   child_vectors <- rbind(child_vectors, repair_vecs)
#   child_vectors <- child_vectors[order(as.numeric(rownames(child_vectors))), ]
# }
```

```{r calculate child typicality}

# typicality calculation
child_sim_matrix <- textSimilarityMatrix(child_vectors)
child_self$typicality <- (rowSums(child_sim_matrix) - 1) / (ncol(child_sim_matrix) - 1) # how else can we calculate typicality??

# 2D coordinates for child cloud
child_umap <- umap(child_vectors)
child_self$umap_1 <- child_umap$layout[,1]
child_self$umap_2 <- child_umap$layout[,2]

```

```{r visualize child semantic cloud}

ggplot(child_self, aes(x = umap_1, y = umap_2, color = typicality)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_viridis_c(option = "plasma", direction = -1) +
  theme_minimal() +
  labs(title = "Child Self-Disclosure Semantic Cloud",
       subtitle = "Dots represent individual child responses",
       color = "Typicality")
```


## adult response analysis 

```{r run adult embeddings}

# adults_self

# run SBERT, minutes from start:  6.387
adult_embeddings_raw <- textEmbed(
  texts = adults_self$response_clean,
  model = "sentence-transformers/all-distilroberta-v1",
  batch_size = 10,
  keep_token_embeddings = FALSE
)

# check if we lost any rows, if TRUE, we're good to go
nrow(adults_self) == nrow(adult_embeddings_raw$texts[[1]])

# pull the vectors
adult_vectors <- adult_embeddings_raw$texts[[1]]

# # if FALSE, run the missing batch
# adult_vectors <- adult_embeddings_raw$texts[[1]]
# 
# # find missing rows
# missing_indices <- setdiff(1:nrow(adults_self), as.numeric(rownames(adult_vectors)))
# 
# # embed missing rows
# repair_adults <- textEmbed(
#   texts = adults_self$response_clean[missing_indices],
#   model = "sentence-transformers/all-distilroberta-v1",
#   batch_size = 1
# )
# 
# # combine and sort
# final_adult_vectors <- rbind(adult_vectors, repair_adults$texts[[1]])
# final_adult_vectors <- final_adult_vectors[order(as.numeric(rownames(final_adult_vectors))), ]

```

```{r calculate adult typicality}

# typicality calculation
adults_sim_matrix <- textSimilarityMatrix(adult_vectors)
adults_self$typicality <- (rowSums(adults_sim_matrix) - 1) / (ncol(adults_sim_matrix) - 1) # how else can we calculate typicality??

# 2D coordinates for adult cloud
adults_umap <- umap(adult_vectors)
adults_self$umap_1 <- adults_umap$layout[,1]
adults_self$umap_2 <- adults_umap$layout[,2]

```

```{r visualize adult semantic cloud}

ggplot(adults_self, aes(x = umap_1, y = umap_2, color = typicality)) +
  geom_point(alpha = 0.4, size = 2) +
  scale_color_viridis_c(option = "plasma", direction = -1) +
  theme_minimal() +
  labs(title = "Adult Self-Disclosure Semantic Cloud",
       subtitle = "Dots represent individual adult responses",
       color = "Typicality")
```