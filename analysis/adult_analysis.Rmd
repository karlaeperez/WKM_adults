---
title: "adult_analysis"
output: html_document
date: "2026-01-20"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(text)
library(here)
library(reticulate)
library(umap)
library(viridis)
library(plotly)

# # install python environment 
# textrpp_install()

# initialize environment 
textrpp_initialize(save_profile = TRUE)

```


### measure of typicality: average cosine similarity
intuition: On average, how much does this specific thought look like every other thought in the database?
here, I calculated typicality within group (i.e., within children, within adults)



```{r import data}

master_data <- read.csv("/Users/karlaperez/Documents/projects/self-disclosure/4. Data/MASTER_DATA_LONG.csv", 
                        stringsAsFactors = FALSE)

child_data <- read.csv("~/Documents/projects/self-disclosure/4. Data/data_children.csv", 
                       stringsAsFactors = FALSE)

```

```{r clean data}

# adults' self disclosure trials -----------------------------------------------
adults_self <- master_data %>% 
  filter(trial_type == "survey-text")

# replace NAs and empty strings with "none"
adults_self$response_clean <- ifelse(is.na(adults_self$response) |
                                      trimws(adults_self$response) == "", 
                                    "none", 
                                    adults_self$response)

# remove newlines and extra spaces
adults_self$response_clean <- gsub("[\r\n]", " ", adults_self$response_clean)
adults_self$response_clean <- trimws(adults_self$response_clean)

message(paste("total adult_self rows to embed:", nrow(adults_self))) # 3000


# adults' animal fluency trials
adults_animals <- master_data %>% 
  filter(trial_type == "animal_entry")

# children's self disclosure trials --------------------------------------------
child_self <- child_data %>% 
  pivot_longer(cols = starts_with("utterance_"), 
               names_to = "utterance",
               names_prefix = "utterance_",
               values_to = "response")

# replace NAs and empty strings with "none"
child_self$response_clean <- ifelse(is.na(child_self$response) |
                                      trimws(child_self$response) == "", 
                                    "none", 
                                    child_self$response)

# remove newlines and extra spaces
child_self$response_clean <- gsub("[\r\n]", " ", child_self$response_clean)
child_self$response_clean <- trimws(child_self$response_clean)

message(paste("total child rows to embed:", nrow(child_self))) # 228


```


```{r run child embeddings}

# run SBERT
child_embeddings_raw <- textEmbed(
  texts = child_self$response_clean,
  model = "sentence-transformers/all-distilroberta-v1",
  batch_size = 10,
  keep_token_embeddings = FALSE
)

# pull the vectors
child_vectors <- child_embeddings_raw$texts[[1]]

# MAKE SURE WE DID NOT LOSE A BATCH 
nrow(child_vectors) == nrow(child_self) # if TRUE, we're good

# if (nrow(child_vectors) < nrow(child_self)) {
#   missing_idx <- setdiff(1:nrow(child_self), as.numeric(rownames(child_vectors)))
#   message(paste("Repairing", length(missing_idx), "missing rows..."))
#   
#   repair <- textEmbed(
#     texts = child_self$response_clean[missing_idx],
#     model = "sentence-transformers/all-distilroberta-v1",
#     batch_size = 1,
#     keep_token_embeddings = FALSE
#   )
#   
#   repair_vecs <- repair$texts[[1]]
#   rownames(repair_vecs) <- missing_idx
#   child_vectors <- rbind(child_vectors, repair_vecs)
#   child_vectors <- child_vectors[order(as.numeric(rownames(child_vectors))), ]
# }
```

```{r calculate child typicality}

# typicality calculation
child_sim_matrix <- textSimilarityMatrix(child_vectors)
child_self$typicality <- (rowSums(child_sim_matrix) - 1) / (ncol(child_sim_matrix) - 1) # how else can we calculate typicality??

# 2D coordinates for child cloud
child_umap <- umap(child_vectors)
child_self$umap_1 <- child_umap$layout[,1]
child_self$umap_2 <- child_umap$layout[,2]

```

```{r visualize child semantic cloud}

ggplot(child_self, aes(x = umap_1, y = umap_2, color = typicality)) +
  geom_point(alpha = 0.7, size = 2) +
  scale_color_viridis_c(option = "plasma", direction = -1) +
  theme_minimal() +
  labs(title = "Child Self-Disclosure Semantic Cloud",
       subtitle = "Dots represent individual child responses",
       color = "Typicality")
```


## adult response analysis 

```{r run adult embeddings}

# adults_self

# run SBERT, minutes from start:  6.387
adult_embeddings_raw <- textEmbed(
  texts = adults_self$response_clean,
  model = "sentence-transformers/all-distilroberta-v1",
  batch_size = 10,
  keep_token_embeddings = FALSE
)

# check if we lost any rows, if TRUE, we're good to go
nrow(adults_self) == nrow(adult_embeddings_raw$texts[[1]])

# pull the vectors
adult_vectors <- adult_embeddings_raw$texts[[1]]

# # if FALSE, run the missing batch
# adult_vectors <- adult_embeddings_raw$texts[[1]]
# 
# # find missing rows
# missing_indices <- setdiff(1:nrow(adults_self), as.numeric(rownames(adult_vectors)))
# 
# # embed missing rows
# repair_adults <- textEmbed(
#   texts = adults_self$response_clean[missing_indices],
#   model = "sentence-transformers/all-distilroberta-v1",
#   batch_size = 1
# )
# 
# # combine and sort
# final_adult_vectors <- rbind(adult_vectors, repair_adults$texts[[1]])
# final_adult_vectors <- final_adult_vectors[order(as.numeric(rownames(final_adult_vectors))), ]

```

```{r calculate adult typicality}

# typicality calculation
adults_sim_matrix <- textSimilarityMatrix(adult_vectors)
adults_self$typicality <- (rowSums(adults_sim_matrix) - 1) / (ncol(adults_sim_matrix) - 1) # how else can we calculate typicality??

# 2D coordinates for adult cloud
adults_umap <- umap(adult_vectors)
adults_self$umap_1 <- adults_umap$layout[,1]
adults_self$umap_2 <- adults_umap$layout[,2]

```

```{r visualize adult semantic cloud}

ggplot(adults_self, aes(x = umap_1, y = umap_2, color = typicality)) +
  geom_point(alpha = 0.4, size = 2) +
  scale_color_viridis_c(option = "plasma", direction = -1) +
  theme_minimal() +
  labs(title = "Adult Self-Disclosure Semantic Cloud",
       subtitle = "Dots represent individual adult responses",
       color = "Typicality")
```

## joint analysis (child and adult)

```{r merge child and adult data}

child_to_merge <- child_self %>%
  mutate(age_group = "child") %>%
  select(age_group, response = response_clean)

adult_to_merge <- adults_self %>%
  mutate(age_group = "adult") %>%
  select(age_group, response = response_clean)

# combine responses
combined_data <- bind_rows(adult_to_merge, child_to_merge)

# combine vectors 
combined_vectors <- rbind(adult_vectors, child_vectors)

message(paste("Total combined responses:", nrow(combined_data)))

```

```{r combined typicality}

# typicality calculation
combined_sim_matrix <- textSimilarityMatrix(combined_vectors)
combined_data$joint_typicality <- (rowSums(combined_sim_matrix) - 1) / (ncol(combined_sim_matrix) - 1)

# 2D coordinates for joint cloud
joint_umap_results <- umap(combined_vectors)
combined_data$umap_1 <- joint_umap_results$layout[,1]
combined_data$umap_2 <- joint_umap_results$layout[,2]
```

```{r cross-group typicality}

# view dimensions
message(paste("Child Vectors Dim:", paste(dim(child_vectors), collapse="x")))
message(paste("Adult Vectors Dim:", paste(dim(adult_vectors), collapse="x")))

# extract only the numeric 768 columns
child_m <- as.matrix(child_vectors[, 1:768])
adult_m <- as.matrix(adult_vectors[, 1:768])

# handle NAs 
child_m[is.na(child_m)] <- 0
adult_m[is.na(adult_m)] <- 0

# normalize
child_norm <- child_m / sqrt(rowSums(child_m^2))
adult_norm <- adult_m / sqrt(rowSums(adult_m^2))

# matrix multiplication: tcrossprod expects (A, B) and calculates A %*% t(B)
sim_matrix <- tcrossprod(child_norm, adult_norm)

message(paste("Resulting Matrix Dim:", paste(dim(sim_matrix), collapse="x")))

child_self$adult_typicality <- rowMeans(sim_matrix)

```

```{r cross group typicality comparisons}

# top 10 most adult-like child disclosures
child_self %>%
  arrange(desc(adult_typicality)) %>%
  select(response, adult_typicality, age_at_test) %>%
  head(10)

# top 10 most child-like child disclosures
child_self %>%
  arrange(adult_typicality) %>%
  select(response, adult_typicality, age_at_test) %>%
  head(10)

```


```{r visualize child and adult data}

ggplot(combined_data, aes(x = umap_1, y = umap_2, color = age_group)) +
  geom_point(alpha = 0.4, size = 1) +
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) + 
  theme_minimal() +
  labs(title = "Integrated Semantic Cloud",
       subtitle = "Adult (Purple) vs. Child (Yellow) Self-Disclosures",
       x = "Joint Semantic Dim 1", y = "Joint Semantic Dim 2") +
  guides(color = guide_legend(override.aes = list(alpha = 1, size = 3)))

ggplot(combined_data, aes(x = umap_1, y = umap_2, color = age_group)) +
  geom_point(alpha = 0.4, size = 1) +
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) + 
  theme_minimal() +
  labs(title = "Integrated Semantic Cloud",
       subtitle = "Adult (Purple) vs. Child (Yellow) Self-Disclosures",
       x = "Joint Semantic Dim 1", y = "Joint Semantic Dim 2") +
  guides(color = guide_legend(override.aes = list(alpha = 1, size = 3)))


```

```{r interactive joint map}

p_joint <- ggplot(combined_data, aes(x = umap_1, y = umap_2, 
                                     color = age_group,
                                     text = response)) +
  geom_point(alpha = 0.5) +
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) +
  theme_minimal()

ggplotly(p_joint, tooltip = "text")

```



```{r}

ggplot(combined_data, aes(x = umap_1, y = umap_2, color = age_group)) +
  geom_point(alpha = 0.5, size = 1.5) + 
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) +
  theme_minimal() +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-3, 10)) + 
  labs(title = "Semantic Intersection")
```


```{r}

ggplot(combined_data, aes(x = umap_1, y = umap_2, color = age_group)) +
  geom_point(alpha = 0.5, size = 1.5) + 
  scale_color_manual(values = c("adult" = "#440154", "child" = "#fde725")) +
  theme_minimal() +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-3, 10)) + 
  labs(title = "zoomed View") +
  facet_wrap(~age_group)

```

```{r}

child_narrow <- child_self %>% 
  select(subject_id, response_clean, typicality, umap_1, umap_2)

adult_narrow <- adults_self %>% 
  select(prolific_id, response_clean, typicality, umap_1, umap_2) %>% 
  rename(subject_id = prolific_id)

combined_data_ids <- rbind(child_narrow, adult_narrow) %>% 
   mutate(age_group = ifelse(startsWith(as.character(subject_id), "WKM"), 
                            "child", 
                            "adult"))

combined_data_ids %>% 
  filter(age_group == "adult") %>% 
  ggplot(aes(x = umap_1, y = umap_2, color = subject_id)) +
  geom_point(alpha = 0.5, size = 1.5) + 
  theme_minimal() +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-6, 6)) + 
  labs(title = "Adults Semantic Cloud",
       subtitle = "Each color represents an individual participant") +
  theme(legend.position = "none")


```

```{r}

combined_data_ids %>% 
  filter(age_group == "child") %>% 
  ggplot(aes(x = umap_1, y = umap_2, color = subject_id)) +
  geom_point(alpha = 0.5, size = 1.5) + 
  theme_minimal() +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-6, 6)) + 
  labs(title = "Children's Semantic Cloud",
       subtitle = "Each color represents an individual participant") +
  theme(legend.position = "none")

```

```{r}

```




